# -*- coding: utf-8 -*-
"""multi-label.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G6KD8jOfcnSS2S_Cktau2W1GexzUIMho
"""

!wget http://nlp.stanford.edu/data/glove.6B.zip
!unzip glove.6B.zip

# #The dataset we use can be downloaded from Kaggle(https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview)
!unzip train.csv.zip
import pandas as pd
df = pd.read_csv("train.csv")

from google.colab import drive
drive.mount('/content/drive')



labels = df[["toxic", "severe_toxic", "obscene", "threat", "insult", "identity_hate"]]
label_counts = labels.sum(axis=0)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib
# matplotlib.use('Agg')
# matplotlib.use('TkAgg')
# %matplotlib inline

import matplotlib.pyplot as plt
plt.figure(figsize=(10,8))
barlist = plt.bar(labels.columns, label_counts)
plt.xticks(labels.columns, label_counts, rotation=60 , size=15)
plt.ylabel('Counts',size=20)
plt.xlabel('Labels',size=20)

plt.show()

print(sum(label_counts))
print(df.shape)

import re
def preprocess_text(sen):
    sentence = re.sub('[^a-zA-Z]', ' ', sen)
    sentence = re.sub(r"\s+[a-zA-Z]\s+", ' ', sentence)
    sentence = re.sub(r'\s+', ' ', sentence)
    return sentence

df['clean'] = df["comment_text"].apply(preprocess_text)
from gensim.utils import simple_preprocess 
df['tokens'] = df['clean'].apply(simple_preprocess)

from sklearn.model_selection import train_test_split

def split_train_test(X, Y, test_size = 0.2, shuffle_state = True ):
    FEATURES = ['tokens','clean']

    X_train, X_test, Y_train, Y_test = train_test_split(
                                                        X[FEATURES],
                                                        Y,
                                                        shuffle = shuffle_state,
                                                        test_size = test_size, 
                                                        random_state = 32)
    X_train = X_train.reset_index()
    X_test = X_test.reset_index()
#     Y_train = Y_train.to_frame()    
#     Y_train = Y_train.reset_index()
#     Y_test = Y_test.to_frame()
#     Y_test = Y_test.reset_index()
    return X_train, X_test, Y_train, Y_test 
X_train, X_test, Y_train, Y_test = split_train_test(df, labels.values )

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
plt.style.use('classic')
# %matplotlib inline
import seaborn as sns
from scipy import stats
#Observe distribution

X_train['freq_word'] = X_train['clean'].apply(lambda x: len(str(x).split()))
X_train['unique_freq_word'] = X_train['clean'].apply(lambda x: len(set(str(x).split())))
                                                 
X_test['freq_word'] = X_test['clean'].apply(lambda x: len(str(x).split()))
X_test['unique_freq_word'] = X_test['clean'].apply(lambda x: len(set(str(x).split())))                  

fig, axes = plt.subplots(ncols=2)
fig.set_size_inches(10,5)

sns.distplot(X_train['freq_word'], bins = 90, ax=axes[0], fit = stats.norm)
(mu0, sigma0) = stats.norm.fit(X_train['freq_word'])
axes[0].legend(['Normal dist. ($\mu=$ {:.2f} and $\sigma=$ {:.2f} )'.format(mu0, sigma0)],loc='best')
axes[0].set_title("Distribution Word Frequency")
axes[0].axvline(X_train['freq_word'].median(), linestyle='dashed')
print("median of word frequency: ", X_train['freq_word'].median())


sns.distplot(X_train['unique_freq_word'], bins = 90, ax=axes[1], color = 'r', fit = stats.norm)
(mu1, sigma1) = stats.norm.fit(X_train['unique_freq_word'])
axes[1].set_title("Distribution Unique Word Frequency")
axes[1].legend(['Normal dist. ($\mu=$ {:.2f} and $\sigma=$ {:.2f} )'.format(mu1, sigma1)],loc='best')
axes[1].axvline(X_train['unique_freq_word'].median(), linestyle='dashed')
print("median of uniuqe word frequency: ", X_train['unique_freq_word'].median())

# Commented out IPython magic to ensure Python compatibility.
from wordcloud import WordCloud, STOPWORDS
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# %matplotlib inline
def cloud(data,backgroundcolor = 'white', width = 800, height = 600):
    wordcloud = WordCloud(stopwords = STOPWORDS, background_color = backgroundcolor,
                         width = width, height = height).generate(data)
    plt.figure(figsize = (15, 10))
    plt.imshow(wordcloud)
    plt.axis("off")
    plt.show()
    
cloud(' '.join(X_train['clean']))

MAX_FEATURES = 5000
EMBEDDING_DIM = 200
VALIDATION_SPLIT = 0.2
MAXLEN =  255 #base on the standard diviaion and mean, we could set this to 255 and cover 95% sentence
BATCH_SIZE = 32
nb_classes =2

from keras.preprocessing.text import Tokenizer
from keras.preprocessing import sequence
from keras.utils import np_utils

tokenizer = Tokenizer(num_words = MAX_FEATURES)
tokenizer.fit_on_texts(X_train['clean'])
sequences_train = tokenizer.texts_to_sequences(X_train['clean'])
sequences_test = tokenizer.texts_to_sequences(X_test['clean'])

X_TRAIN = sequence.pad_sequences(sequences_train, maxlen = MAXLEN)
X_TEST = sequence.pad_sequences(sequences_test, maxlen = MAXLEN)

Y_TRAIN = Y_train #np_utils.to_categorical(Y_train, nb_classes)
Y_TEST = Y_test #np_utils.to_categorical(Y_test, nb_classes)

df.describe()

fig , axes = plt.subplots(2,3,figsize = (10,10), constrained_layout = True)
sns.countplot(ax=axes[0,0],x='toxic',data=df )
sns.countplot(ax=axes[0,1],x='severe_toxic',data=df)
sns.countplot(ax=axes[0,2],x='obscene',data=df)
sns.countplot(ax = axes[1,0],x='threat',data=df)
sns.countplot(ax=axes[1,1],x='insult',data=df)
sns.countplot(ax=axes[1,2],x='identity_hate',data=df)
plt.suptitle('No Of Classes Of Each Category')
plt.show()

from gensim.scripts.glove2word2vec import glove2word2vec
glove_input_file = 'glove.6B.300d.txt'
word2vec_output_file = 'glove.6B.300d.txt.w2v'
glove2word2vec(glove_input_file, word2vec_output_file)

from gensim.models import KeyedVectors
# load the Stanford GloVe model 
model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)
# model.save("Glove_word2vec.model")

# model['computer'] 
words, vectors = [], []
for k,v in model.vocab.items():
    words.append(k)
    vectors.append(model[k])
# model.vocab.keys()

import numpy
vocab_size = len(tokenizer.word_index) + 1
embedding_matrix = numpy.zeros((vocab_size, 300))
for word, index in tokenizer.word_index.items():
    if word in model:
        embedding_matrix[index] = model[word]

batch_size = 512
from  keras import Sequential
from keras.layers import *
lstm_model = Sequential()
lstm_model.add(Embedding(vocab_size, 300, weights = [embedding_matrix], trainable = False))
lstm_model.add(LSTM(128))
lstm_model.add(Dense(6, activation='relu'))

lstm_model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['acc'])



lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])

print('Training...')
history = lstm_model.fit(X_TRAIN, Y_TRAIN, batch_size=batch_size, epochs = 15)
score, acc = lstm_model.evaluate(X_TEST, Y_TEST,
                            batch_size=batch_size)

print('Test accuracy:', acc)
print("Generating test predictions...")

X_TRAIN, Y_TRAIN



print(lstm_model.summary())

from keras.utils import plot_model
plot_model(lstm_model, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)

score = lstm_model.evaluate(X_TEST, Y_TEST, verbose=1)

print("Test Score:", score[0])
print("Test Accuracy:", score[1])

import matplotlib.pyplot as plt

plt.plot(history.history['acc'])
# plt.plot(history.history['val_acc'])

plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
# plt.plot(history.history['val_loss'])

plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

from sklearn.metrics import classification_report
train_predict = lstm_model.predict_classes(X_TRAIN, verbose=0)
test_predict = lstm_model.predict_classes(X_TEST, verbose=0)

print(">> training set \n")
from sklearn.metrics import classification_report
# print(classification_report(Y_TRAIN, train_predict, target_names= ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult',
#        'identity_hate']))
# # print(classification_report(Y_TRAIN,train_predict))
# # print(">> testing set \n")
# # print(classification_reportY_TEST,test_predict)
train_predict

train_predict.shape

X_TRAIN